{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Use ICA to separate a 100 gecs song into its components\n\nWe'll use the \"Most Wanted Person in the United States\" stems from the 10,000 gecs\nstems pack to demonstrate how to use ICA to separate the components of a song.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport IPython.display as ipd\n\nimport numpy as np\n\nfrom sklearn.decomposition import FastICA\n\nfrom scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the mixed audio\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SOURCES_DIR = (\n    Path(\".\").expanduser().resolve().parent /\n    \"assets\" /\n    \"mixed_audio\"\n)\nassert SOURCES_DIR.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sfreq, drums_mic = wavfile.read(SOURCES_DIR / \"drums.wav\")\nbass_mic = wavfile.read(SOURCES_DIR / \"bass.wav\")[1]\nguitars_mic = wavfile.read(SOURCES_DIR / \"guitars.wav\")[1]\nfx_mic = wavfile.read(SOURCES_DIR / \"fx.wav\")[1]\nvocals_mic = wavfile.read(SOURCES_DIR / \"vocals.wav\")[1]\nmix = drums_mic + bass_mic + guitars_mic + fx_mic + vocals_mic\nmix = mix / mix.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here is the mixed audio, and the bass, fx, and vocals isolated (for reference)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(mix, rate=sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(bass_mic, rate=sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(vocals_mic, rate=sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(fx_mic, rate=sfreq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Separate the components with ICA\nWe'll stack our \"observations\" (the microphone recordings) into a matrix.\nEach column will be a different microphone, and each row will be a different\ntime point. We'll then use ICA to separate the components. By components, we\nmean the original sources that were mixed together to create the microphone\nrecordings (drums, bass, guitars, fx, and vocals).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "microphones = np.vstack([drums_mic, bass_mic, guitars_mic, fx_mic, vocals_mic]).T\nica = FastICA()\ncomponents = ica.fit_transform(microphones)\n# Unpack the components\nic_1, ic_2, ic_3, ic_4, ic_5 = components.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here are the separated components\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(ic_1, rate=sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(ic_2, rate=sfreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ipd.Audio(ic_3, rate=sfreq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Not too bad!\nThe ICA algorithm was able to separate the components pretty well.\nThe separated components are not exactly the same as the original sources, but\nthey are pretty close. The ICA algorithm is able to separate the components\nbecause the sources are statistically independent. This is a pretty cool\ndemonstration of the power of ICA!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}