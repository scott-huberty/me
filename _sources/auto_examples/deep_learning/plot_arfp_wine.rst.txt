
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/deep_learning/plot_arfp_wine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_deep_learning_plot_arfp_wine.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_deep_learning_plot_arfp_wine.py:


Compute Accuracy, Precision, Recall, and F1 on the Wine dataset
================================================================

We'll use Scikit Learn to compute these metrics for us.

.. GENERATED FROM PYTHON SOURCE LINES 10-29

.. code-block:: Python

    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    from sklearn.metrics import (
      accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
      )
    from sklearn.model_selection import train_test_split

    # for number-crunching
    import numpy as np

    # for dataset management
    import polars as pl

    # for data visualization
    import matplotlib.pyplot as plt
    import seaborn as sns








.. GENERATED FROM PYTHON SOURCE LINES 30-35

Load the Wine dataset
---------------------
We'll use the Wine dataset from the UCI Machine Learning Repository.
We'll create a new variable, "good_quality". If the wine quality is greater than 5,
we'll set "good_quality" to 1 (True), otherwise we'll set it to 0 (False).

.. GENERATED FROM PYTHON SOURCE LINES 37-59

.. code-block:: Python

    url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
    df = pl.read_csv(url, separator=";", infer_schema_length=int(1e5))
    df = df.rename(lambda col_name : col_name.replace(" ", "_"))
    # Drop a few outliers
    df = df.filter(df["total_sulfur_dioxide"] < 200)

    z_scores = [
        (pl.col(col) - pl.col(col).mean()) / pl.col(col).std()
        for col in df.columns
        if col != "quality"
        ]
    df = df.select([
        pl.col("quality"),
        *z_scores
    ])

    # create a new column for binarized (boolean) quality
    df = df.with_columns(
        pl.when(df["quality"] > 5).then(1).otherwise(0).alias("good_quality")
    )
    df






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div><style>
    .dataframe > thead > tr,
    .dataframe > tbody > tr {
      text-align: right;
      white-space: pre-wrap;
    }
    </style>
    <small>shape: (1_597, 13)</small><table border="1" class="dataframe"><thead><tr><th>quality</th><th>fixed_acidity</th><th>volatile_acidity</th><th>citric_acid</th><th>residual_sugar</th><th>chlorides</th><th>free_sulfur_dioxide</th><th>total_sulfur_dioxide</th><th>density</th><th>pH</th><th>sulphates</th><th>alcohol</th><th>good_quality</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td></tr></thead><tbody><tr><td>5</td><td>-0.528185</td><td>0.960356</td><td>-1.391387</td><td>-0.452437</td><td>-0.244571</td><td>-0.464413</td><td>-0.382415</td><td>0.556633</td><td>1.288066</td><td>-0.580034</td><td>-0.959006</td><td>0</td></tr><tr><td>5</td><td>-0.29858</td><td>1.965999</td><td>-1.391387</td><td>0.049005</td><td>0.222757</td><td>0.876758</td><td>0.654456</td><td>0.025914</td><td>-0.723425</td><td>0.127797</td><td>-0.583159</td><td>0</td></tr><tr><td>5</td><td>-0.29858</td><td>1.29557</td><td>-1.185609</td><td>-0.165899</td><td>0.095304</td><td>-0.081221</td><td>0.245992</td><td>0.132058</td><td>-0.334104</td><td>-0.049161</td><td>-0.583159</td><td>0</td></tr><tr><td>6</td><td>1.653061</td><td>-1.386143</td><td>1.489509</td><td>-0.452437</td><td>-0.265814</td><td>0.110375</td><td>0.434514</td><td>0.662777</td><td>-0.982972</td><td>-0.462063</td><td>-0.583159</td><td>1</td></tr><tr><td>5</td><td>-0.528185</td><td>0.960356</td><td>-1.391387</td><td>-0.452437</td><td>-0.244571</td><td>-0.464413</td><td>-0.382415</td><td>0.556633</td><td>1.288066</td><td>-0.580034</td><td>-0.959006</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>5</td><td>-1.216999</td><td>0.401666</td><td>-0.979831</td><td>-0.380803</td><td>0.05282</td><td>1.547343</td><td>-0.068212</td><td>-0.982451</td><td>0.898745</td><td>-0.462063</td><td>0.074575</td><td>0</td></tr><tr><td>6</td><td>-1.389203</td><td>0.122321</td><td>-0.876942</td><td>-0.237533</td><td>-0.541962</td><td>2.217928</td><td>0.151731</td><td>-0.865693</td><td>1.352953</td><td>0.599684</td><td>0.732309</td><td>1</td></tr><tr><td>6</td><td>-1.159598</td><td>-0.101155</td><td>-0.722608</td><td>-0.165899</td><td>-0.244571</td><td>1.259949</td><td>-0.193893</td><td>-0.536647</td><td>0.704085</td><td>0.540698</td><td>0.544385</td><td>1</td></tr><tr><td>5</td><td>-1.389203</td><td>0.653076</td><td>-0.774052</td><td>-0.380803</td><td>-0.265814</td><td>1.547343</td><td>-0.068212</td><td>-0.679941</td><td>1.677387</td><td>0.304754</td><td>-0.207311</td><td>0</td></tr><tr><td>6</td><td>-1.331802</td><td>-1.218536</td><td>1.026508</td><td>0.765351</td><td>-0.435751</td><td>0.206172</td><td>-0.131053</td><td>-0.669327</td><td>0.509424</td><td>0.009825</td><td>0.544385</td><td>1</td></tr></tbody></table></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 60-65

Convert to torch tensors
------------------------

Note that we pass all columns except "quality" and "good_quality" to the input tensor.
The target tensor is the "good_quality" boolean variable column.

.. GENERATED FROM PYTHON SOURCE LINES 67-73

.. code-block:: Python

    train_tensor = df.select(
        [col for col in df.columns if col not in ["quality", "good_quality"]]
    ).to_torch().float()
    labels_tensor = df.select("good_quality").to_torch().float()
    print(f"train_tensor shape: {train_tensor.shape}", f"labels_tensor shape: {labels_tensor.shape}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    train_tensor shape: torch.Size([1597, 11]) labels_tensor shape: torch.Size([1597, 1])




.. GENERATED FROM PYTHON SOURCE LINES 74-77

Split the data
--------------


.. GENERATED FROM PYTHON SOURCE LINES 79-89

.. code-block:: Python

    train_data, test_data, train_labels, test_labels = train_test_split(train_tensor, labels_tensor, test_size=.1)
    # then convert them into PyTorch Datasets (note: already converted to tensors)
    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)
    test_dataset = torch.utils.data.TensorDataset(test_data, test_labels)

    # Finally, create the DataLoader objects
    n_samples = test_dataset.tensors[0].shape[0] 
    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, drop_last=True)
    test_loader = DataLoader(dataset=test_dataset, batch_size=n_samples, shuffle=False)








.. GENERATED FROM PYTHON SOURCE LINES 90-96

Define the model
----------------

Note that we have 11 input features and 1 output feature (the target), which
match the number of columns in ``train_tensor`` and ``labels_tensor``, respectively.


.. GENERATED FROM PYTHON SOURCE LINES 98-119

.. code-block:: Python

    class WineNet(nn.Module):
      def __init__(self):
        super().__init__()

        ### input layer
        self.input = nn.Linear(11, 16)
    
        ### hidden layers
        self.fc1 = nn.Linear(16, 32)
        self.fc2 = nn.Linear(32, 32)

        ### output layer
        self.output = nn.Linear(32, 1)
  
      # forward pass
      def forward(self, x):
        x = F.relu( self.input(x) )
        x = F.relu( self.fc1(x) )
        x = F.relu( self.fc2(x) )
        return self.output(x)








.. GENERATED FROM PYTHON SOURCE LINES 120-126

Train the model
------------------------------------

We want to train the model to predict whether a wine is of good quality or not, based
on the wine characteristics.


.. GENERATED FROM PYTHON SOURCE LINES 128-175

.. code-block:: Python

    wine_net = WineNet()
    num_epochs = 500
    # loss function and optimizer
    lossfun = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.SGD(wine_net.parameters(), lr=.01)

    # initialize losses
    losses   = torch.zeros(num_epochs)
    train_accuracies = []
    test_accuracies  = []

    # loop over epochs
    for epochi in range(num_epochs):
        # loop over training data batches
        batch_accuracies  = []
        batch_losses = []
        for x, y in train_loader:
            # forward pass and loss
            y_hat = wine_net(x)
            loss = lossfun(y_hat , y)

            # backprop
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # loss from this batch
            batch_losses.append(loss.item())

            # compute training accuracy for this batch
            accuracy = 100 * torch.mean(((y_hat > 0) == y).float()).item()
            batch_accuracies.append(accuracy)
            # end of batch loop...

        # now that we've trained through the batches, get their average training accuracy
        train_accuracies.append( np.mean(batch_accuracies) )

        # and get average losses across the batches
        losses[epochi] = np.mean(batch_losses)

        # test accuracy
        x, y = next(iter(test_loader)) # extract X, y from test dataloader
        with torch.no_grad(): # deactivates autograd
            y_hat = wine_net(x)
            test_acc = 100 * torch.mean(((y_hat > 0) == y).float()).item()
            test_accuracies.append(test_acc)








.. GENERATED FROM PYTHON SOURCE LINES 176-179

Compute the accuracy, precision, recall, and F1 score on the train and test sets
----------------------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 181-207

.. code-block:: Python

    train_predictions = wine_net(train_loader.dataset.tensors[0])
    test_predictions = wine_net(test_loader.dataset.tensors[0])

    # initialize a dictionary to store the metrics
    train_metrics = [0, 0, 0, 0]
    test_metrics = [0, 0, 0, 0]

    # compute the metrics on the train set
    true_labels = train_loader.dataset.tensors[1]
    train_predictions = train_predictions > 0
    train_metrics[0] = accuracy_score(true_labels, train_predictions)
    train_metrics[1] = precision_score(true_labels, train_predictions)
    train_metrics[2] = recall_score(true_labels, train_predictions)
    train_metrics[3] = f1_score(true_labels, train_predictions)

    # compute the metrics on the test set
    true_labels = test_loader.dataset.tensors[1]
    test_predictions = test_predictions > 0
    test_metrics[0] = accuracy_score(true_labels, test_predictions)
    test_metrics[1] = precision_score(true_labels, test_predictions)
    test_metrics[2] = recall_score(true_labels, test_predictions)
    test_metrics[3] = f1_score(true_labels, test_predictions)
    for i, metric in enumerate(['Accuracy', 'Precision', 'Recall', 'F1-score']):
        print(f'{metric} (train): {train_metrics[i]:.2f}')
        print(f'{metric} (test): {test_metrics[i]:.2f}')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Accuracy (train): 0.82
    Accuracy (test): 0.74
    Precision (train): 0.83
    Precision (test): 0.72
    Recall (train): 0.83
    Recall (test): 0.81
    F1-score (train): 0.83
    F1-score (test): 0.76




.. GENERATED FROM PYTHON SOURCE LINES 208-211

Plot the metrics
----------------


.. GENERATED FROM PYTHON SOURCE LINES 213-224

.. code-block:: Python

    sns.set_style("darkgrid")
    fig, ax = plt.subplots()

    ax.bar(np.arange(4) -.1, train_metrics, .5)
    ax.bar(np.arange(4) +.1, test_metrics, .5)
    ax.set_xticks([0, 1, 2, 3], ['Accuracy', 'Precision', 'Recall', 'F1-score'])
    ax.set_ylim([.6,1])
    ax.legend(['Train', 'Test'])
    ax.set_title('Performance metrics')
    plt.show()




.. image-sg:: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_001.png
   :alt: Performance metrics
   :srcset: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 225-228

Show the confusion matrices
---------------------------


.. GENERATED FROM PYTHON SOURCE LINES 230-231

Confusion matrices

.. GENERATED FROM PYTHON SOURCE LINES 231-271

.. code-block:: Python

    true_labels_train = train_loader.dataset.tensors[1]
    true_labels_test = test_loader.dataset.tensors[1]
    train_conf = confusion_matrix(true_labels_train, train_predictions>0)
    test_conf  = confusion_matrix(true_labels_test, test_predictions>0)

    sns.set_style('white')
    fig, axes = plt.subplots(1, 2, figsize=(10,4))

    # Confusion Matrix (train)
    axes[0].imshow(train_conf, 'Blues', vmax=len(train_predictions)/2)
    axes[0].set_xticks([0,1])
    axes[0].set_yticks([0,1])
    axes[0].set_xticklabels(['bad','good'])
    axes[0].set_yticklabels(['bad','good'])
    axes[0].set_xlabel('Predicted quality')
    axes[0].set_ylabel('True quality')
    axes[0].set_title('TRAIN confusion matrix')

    # add text labels
    text_kwargs = dict(ha='center', va='center')
    axes[0].text(0, 0, f'True negatives:\n{train_conf[0, 0]}' , **text_kwargs)
    axes[0].text(0, 1, f'False negatives:\n{train_conf[1, 0]}', **text_kwargs)
    axes[0].text(1, 1, f'True positives:\n{train_conf[1, 1]}' , **text_kwargs)
    axes[0].text(1, 0, f'False positives:\n{train_conf[0, 1]}', **text_kwargs)

    # Confusion Matrix (test)
    axes[1].imshow(test_conf, 'Blues', vmax=len(test_predictions)/2)
    axes[1].set_xticks([0,1])
    axes[1].set_yticks([0,1])
    axes[1].set_xticklabels(['bad','good'])
    axes[1].set_yticklabels(['bad','good'])
    axes[1].set_xlabel('Predicted quality')
    axes[1].set_ylabel('True quality')
    axes[1].set_title('TEST confusion matrix')

    # add text labels
    axes[1].text(0, 0, f'True negatives:\n{test_conf[0,0]}', **text_kwargs)
    axes[1].text(0, 1, f'False negatives:\n{test_conf[1,0]}', **text_kwargs)
    axes[1].text(1, 1, f'True positives:\n{test_conf[1,1]}' , **text_kwargs)
    axes[1].text(1, 0, f'False positives:\n{test_conf[0,1]}', **text_kwargs)
    plt.show()


.. image-sg:: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_002.png
   :alt: TRAIN confusion matrix, TEST confusion matrix
   :srcset: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (2 minutes 38.054 seconds)


.. _sphx_glr_download_auto_examples_deep_learning_plot_arfp_wine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_arfp_wine.ipynb <plot_arfp_wine.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_arfp_wine.py <plot_arfp_wine.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_arfp_wine.zip <plot_arfp_wine.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
