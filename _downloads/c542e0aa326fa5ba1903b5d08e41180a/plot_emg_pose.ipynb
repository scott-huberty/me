{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Predict hand pose from EMG signals using ML\n\nMeta has been doing a lot of work trying to figure out how to replace\nkeyboards and controllers with hand gestures (when the user is wearing\na wrist band). \n\nBack when I was a young hopper (AKA a PhD student), I interviewed with\ntheir Reality Labs team. The technical interview at the time was to\ntake a dataset of EMG signals from a participant, and to predict the\nhand pose of the participant (Also, nearly pure python.. I.e. no\nscikit-learn, no pytorch. Woof).\n\nWell now they've open-sourced the EMG dataset from that project, so\nI am going to save some soul out there some time and show how them\nhow to do it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from collections.abc import KeysView\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Any, ClassVar\n\nimport h5py\nimport matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nimport pooch\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a helper function to read the data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@dataclass\nclass Emg2PoseSessionData:\n    \"\"\"A read-only interface to a single emg2pose session file stored in\n    HDF5 format.\n\n    ``self.timeseries`` is a `h5py.Dataset` instance with a compound data type\n    as in a numpy structured array containing three fields - EMG data from the\n    left and right wrists, and their corresponding timestamps.\n    The sampling rate of EMG is 2kHz, each EMG device has 16 electrode\n    channels, and the signal has been high-pass filtered. Therefore, the fields\n    corresponding to left and right EMG are 2D arrays of shape ``(T, 16)`` each\n    and ``timestamps`` is a 1D array of length ``T``.\n\n    NOTE: Only the metadata and ground-truth are loaded into memory while the\n    EMG data is accesssed directly from disk. When wrapping this interface\n    within a PyTorch Dataset, use multiple dataloading workers to mask the\n    disk seek and read latencies.\"\"\"\n\n    HDF5_GROUP: ClassVar[str] = \"emg2pose\"\n    # timeseries keys\n    TIMESERIES: ClassVar[str] = \"timeseries\"\n    EMG: ClassVar[str] = \"emg\"\n    JOINT_ANGLES: ClassVar[str] = \"joint_angles\"\n    TIMESTAMPS: ClassVar[str] = \"time\"\n    # metadata keys\n    SESSION_NAME: ClassVar[str] = \"session\"\n    SIDE: ClassVar[str] = \"side\"\n    STAGE: ClassVar[str] = \"stage\"\n    START_TIME: ClassVar[str] = \"start\"\n    END_TIME: ClassVar[str] = \"end\"\n    NUM_CHANNELS: ClassVar[str] = \"num_channels\"\n    DATASET_NAME: ClassVar[str] = \"dataset\"\n    USER: ClassVar[str] = \"user\"\n    SAMPLE_RATE: ClassVar[str] = \"sample_rate\"\n\n    hdf5_path: Path\n\n    def __post_init__(self) -> None:\n        self._file = h5py.File(self.hdf5_path, \"r\")\n        emg2pose_group: h5py.Group = self._file[self.HDF5_GROUP]\n\n        # ``timeseries`` is a HDF5 compound Dataset\n        self.timeseries: h5py.Dataset = emg2pose_group[self.TIMESERIES]\n        assert self.timeseries.dtype.fields is not None\n        assert self.EMG in self.timeseries.dtype.fields\n        assert self.JOINT_ANGLES in self.timeseries.dtype.fields\n        assert self.TIMESTAMPS in self.timeseries.dtype.fields\n\n        # Load the metadata entirely into memory as it's rather small\n        self.metadata: dict[str, Any] = {}\n        for key, val in emg2pose_group.attrs.items():\n            self.metadata[key] = val\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback) -> None:\n        self._file.close()\n\n    def __len__(self) -> int:\n        return len(self.timeseries)\n\n    def __getitem__(self, key: slice) -> np.ndarray:\n        return self.timeseries[key]\n\n    def slice(self, start_t: float = -np.inf, end_t: float = np.inf) -> np.ndarray:\n        \"\"\"Load and return a contiguous slice of the timeseries windowed\n        by the provided start and end timestamps.\n\n        Args:\n            start_t (float): The start time of the window to grab\n                (in absolute unix time). Defaults to selecting from the\n                beginning of the session. (default: ``-np.inf``).\n            end_t (float): The end time of the window to grab\n                (in absolute unix time). Defaults to selecting until the\n                end of the session. (default: ``np.inf``)\n        \"\"\"\n        start_idx, end_idx = self.timestamps.searchsorted([start_t, end_t])\n        return self[start_idx:end_idx]\n\n    @property\n    def fields(self) -> KeysView[str]:\n        \"\"\"The names of the fields in ``timeseries``.\"\"\"\n        fields: KeysView[str] = self.timeseries.dtype.fields.keys()\n        return fields\n\n    @property\n    def timestamps(self) -> np.ndarray:\n        \"\"\"EMG timestamps.\n\n        NOTE: This reads the entire sequence of timesetamps from the underlying\n        HDF5 file and therefore incurs disk latency. Avoid this in the critical\n        path.\"\"\"\n        emg_timestamps = self.timeseries[self.TIMESTAMPS]\n        assert (np.diff(emg_timestamps) >= 0).all(), \"Not monotonic\"\n        return emg_timestamps\n\n    @property\n    def session_name(self) -> str:\n        \"\"\"Unique name of the session.\"\"\"\n        return self.metadata[self.SESSION_NAME]\n\n    @property\n    def user(self) -> str:\n        \"\"\"Unique ID of the user this session corresponds to.\"\"\"\n        return self.metadata[self.USER]\n\n    def __str__(self) -> str:\n        return f\"{self.__class__.__name__} {self.session_name} ({len(self)} samples)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the dataset\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = Path.home() / \"emg_data\"\nemg_dir = data_dir / \"emg2pose_dataset_mini\"\nwant_fpath = \"emg2pose_dataset_mini/2022-12-06-1670313600-e3096-cv-emg-pose-train@2-recording-1_left.hdf5\"\n\nunpack = pooch.Untar(extract_dir=data_dir, # Relative to the path where the zip file is downloaded\n                     members=[want_fpath]\n                     )\nemg_fpaths = pooch.retrieve(\n    url=\"https://fb-ctrl-oss.s3.amazonaws.com/emg2pose/emg2pose_dataset_mini.tar\",\n    known_hash=\"sha256:d7400e98508ccbb2139c2d78e552867b23501f637456546fd6680f3fe7fec50d\",\n    progressbar=True,\n    path=data_dir,\n    processor=unpack,\n)\nemg_fname = Path(emg_fpaths[0])\nemg_dir = emg_fname.parent\n# Delete the large tar file\n# list(emg_dir.glob(\"*.tar\"))[0].unlink()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = Emg2PoseSessionData(hdf5_path=emg_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the data\nWe'll let MNE-Python do the heavy lifting for us here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ch_names = [f\"EMG{ii:02}\" for ii, _ in enumerate(data[\"emg\"].T, 1)]\nch_types = [\"emg\"] * len(ch_names)\nsfreq = data.metadata[Emg2PoseSessionData.SAMPLE_RATE]\ninfo = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n# MNE expects data in the shape (n_channels, n_times). So we need to transpose the data\nraw = mne.io.RawArray(data[\"emg\"].T, info)\n# MNE expects the EMG data to be in Volts, so we need to scale it from mV to V\nraw.apply_function(lambda x: x * 1e-6, picks=\"emg\")\nraw.plot(start=20, duration=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use PCA and KMeans to cluster the data\n\nWe'll use PCA to reduce the data dimenstionality to 3D\nand then use KMeans to cluster the data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_components = 3\npca = PCA(n_components=n_components)\ndata_pca = pca.fit_transform(data[\"emg\"])\nclusters = KMeans(n_clusters=5).fit_predict(data_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the clusters\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"darkgrid\")\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\nax.scatter(data_pca[:, 0], data_pca[:, 1], data_pca[:, 2], c=clusters)\nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nax.set_zlabel(\"PC3\")\nax.set_title(\"PCA of EMG data with KMeans clustering\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}