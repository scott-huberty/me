
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/deep_learning/plot_arfp_wine.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_deep_learning_plot_arfp_wine.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_deep_learning_plot_arfp_wine.py:


Computer Accuracy, Precision, Recaall, and F1 on the Wine dataset
=================================================================

Let's practice computing the accuracy, precision, recall, and F1 score on the Wine dataset.
We'll also use Scikit Learn to compute these metrics for us.

.. GENERATED FROM PYTHON SOURCE LINES 11-28

.. code-block:: Python

    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    from sklearn.model_selection import train_test_split

    # for number-crunching
    import numpy as np

    # for dataset management
    import polars as pl

    # for data visualization
    import matplotlib.pyplot as plt
    import matplotlib_inline.backend_inline
    import seaborn as sns








.. GENERATED FROM PYTHON SOURCE LINES 29-35

Load the Wine dataset
---------------------
We'll use the Wine dataset from the UCI Machine Learning Repository.
The dataset has 178 samples with 13 features each.
The features are chemical properties of the wines.
The target variable is the wine class (1, 2, or 3).

.. GENERATED FROM PYTHON SOURCE LINES 37-59

.. code-block:: Python

    url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
    df = pl.read_csv(url, separator=";", infer_schema_length=int(1e5))
    df = df.rename(lambda col_name : col_name.replace(" ", "_"))
    # Drop a few outliers
    df = df.filter(df["total_sulfur_dioxide"] < 200)

    z_scores = [
        (pl.col(col) - pl.col(col).mean()) / pl.col(col).std()
        for col in df.columns
        if col != "quality"
        ]
    df = df.select([
        pl.col("quality"),
        *z_scores
    ])

    # create a new column for binarized (boolean) quality
    df = df.with_columns(
        pl.when(df["quality"] > 5).then(1).otherwise(0).alias("good_quality")
    )
    df






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div><style>
    .dataframe > thead > tr,
    .dataframe > tbody > tr {
      text-align: right;
      white-space: pre-wrap;
    }
    </style>
    <small>shape: (1_597, 13)</small><table border="1" class="dataframe"><thead><tr><th>quality</th><th>fixed_acidity</th><th>volatile_acidity</th><th>citric_acid</th><th>residual_sugar</th><th>chlorides</th><th>free_sulfur_dioxide</th><th>total_sulfur_dioxide</th><th>density</th><th>pH</th><th>sulphates</th><th>alcohol</th><th>good_quality</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td></tr></thead><tbody><tr><td>5</td><td>-0.528185</td><td>0.960356</td><td>-1.391387</td><td>-0.452437</td><td>-0.244571</td><td>-0.464413</td><td>-0.382415</td><td>0.556633</td><td>1.288066</td><td>-0.580034</td><td>-0.959006</td><td>0</td></tr><tr><td>5</td><td>-0.29858</td><td>1.965999</td><td>-1.391387</td><td>0.049005</td><td>0.222757</td><td>0.876758</td><td>0.654456</td><td>0.025914</td><td>-0.723425</td><td>0.127797</td><td>-0.583159</td><td>0</td></tr><tr><td>5</td><td>-0.29858</td><td>1.29557</td><td>-1.185609</td><td>-0.165899</td><td>0.095304</td><td>-0.081221</td><td>0.245992</td><td>0.132058</td><td>-0.334104</td><td>-0.049161</td><td>-0.583159</td><td>0</td></tr><tr><td>6</td><td>1.653061</td><td>-1.386143</td><td>1.489509</td><td>-0.452437</td><td>-0.265814</td><td>0.110375</td><td>0.434514</td><td>0.662777</td><td>-0.982972</td><td>-0.462063</td><td>-0.583159</td><td>1</td></tr><tr><td>5</td><td>-0.528185</td><td>0.960356</td><td>-1.391387</td><td>-0.452437</td><td>-0.244571</td><td>-0.464413</td><td>-0.382415</td><td>0.556633</td><td>1.288066</td><td>-0.580034</td><td>-0.959006</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>5</td><td>-1.216999</td><td>0.401666</td><td>-0.979831</td><td>-0.380803</td><td>0.05282</td><td>1.547343</td><td>-0.068212</td><td>-0.982451</td><td>0.898745</td><td>-0.462063</td><td>0.074575</td><td>0</td></tr><tr><td>6</td><td>-1.389203</td><td>0.122321</td><td>-0.876942</td><td>-0.237533</td><td>-0.541962</td><td>2.217928</td><td>0.151731</td><td>-0.865693</td><td>1.352953</td><td>0.599684</td><td>0.732309</td><td>1</td></tr><tr><td>6</td><td>-1.159598</td><td>-0.101155</td><td>-0.722608</td><td>-0.165899</td><td>-0.244571</td><td>1.259949</td><td>-0.193893</td><td>-0.536647</td><td>0.704085</td><td>0.540698</td><td>0.544385</td><td>1</td></tr><tr><td>5</td><td>-1.389203</td><td>0.653076</td><td>-0.774052</td><td>-0.380803</td><td>-0.265814</td><td>1.547343</td><td>-0.068212</td><td>-0.679941</td><td>1.677387</td><td>0.304754</td><td>-0.207311</td><td>0</td></tr><tr><td>6</td><td>-1.331802</td><td>-1.218536</td><td>1.026508</td><td>0.765351</td><td>-0.435751</td><td>0.206172</td><td>-0.131053</td><td>-0.669327</td><td>0.509424</td><td>0.009825</td><td>0.544385</td><td>1</td></tr></tbody></table></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 60-63

Convert to torch tensors
------------------------


.. GENERATED FROM PYTHON SOURCE LINES 65-71

.. code-block:: Python

    train_tensor = df.select(
        [col for col in df.columns if col not in ["quality", "good_quality"]]
    ).to_torch().float()
    labels_tensor = df.select("good_quality").to_torch().float()
    print(train_tensor.shape, labels_tensor.shape)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    torch.Size([1597, 11]) torch.Size([1597, 1])




.. GENERATED FROM PYTHON SOURCE LINES 72-75

Split the data
--------------
We'll plit the data into training and testing sets using Scikit Learn

.. GENERATED FROM PYTHON SOURCE LINES 77-87

.. code-block:: Python

    train_data, test_data, train_labels, test_labels = train_test_split(train_tensor, labels_tensor, test_size=.1)
    # then convert them into PyTorch Datasets (note: already converted to tensors)
    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)
    test_dataset = torch.utils.data.TensorDataset(test_data, test_labels)

    # Finally, create the DataLoader objects
    n_samples = test_dataset.tensors[0].shape[0] 
    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, drop_last=True)
    test_loader = DataLoader(dataset=test_dataset, batch_size=n_samples, shuffle=False)








.. GENERATED FROM PYTHON SOURCE LINES 88-91

Define the model
----------------


.. GENERATED FROM PYTHON SOURCE LINES 93-114

.. code-block:: Python

    class WineNet(nn.Module):
      def __init__(self):
        super().__init__()

        ### input layer
        self.input = nn.Linear(11,16)
    
        ### hidden layers
        self.fc1 = nn.Linear(16,32)
        self.fc2 = nn.Linear(32,32)

        ### output layer
        self.output = nn.Linear(32,1)
  
      # forward pass
      def forward(self,x):
        x = F.relu( self.input(x) )
        x = F.relu( self.fc1(x) )
        x = F.relu( self.fc2(x) )
        return self.output(x)








.. GENERATED FROM PYTHON SOURCE LINES 115-118

Define a function to train the model
------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 120-182

.. code-block:: Python

    def train_the_model(
        wine_net,
        train_loader,
        test_loader,
        num_epochs=1_000,
        ):
      """Train the model on the Wine dataset.

      Parameters
      ----------
      wine_net : WineNet
        The neural network model defined above
      num_epochs : int
        The number of epochs to train the model
      """
      # loss function and optimizer
      lossfun = nn.BCEWithLogitsLoss()
      optimizer = torch.optim.SGD(wine_net.parameters(),lr=.01)

      # initialize losses
      losses   = torch.zeros(num_epochs)
      train_accuracies = []
      test_accuracies  = []

      # loop over epochs
      for epochi in range(num_epochs):

        # loop over training data batches
        batch_accuracies  = []
        batch_losses = []
        for x, y in train_loader:
          # forward pass and loss
          y_hat = wine_net(x)
          loss = lossfun(y_hat , y)

          # backprop
          optimizer.zero_grad()
          loss.backward()
          optimizer.step()

          # loss from this batch
          batch_losses.append(loss.item())

          # compute training accuracy for this batch
          batch_accuracies.append( 100 * torch.mean(((y_hat > 0) == y).float()).item() )
        # end of batch loop...

        # now that we've trained through the batches, get their average training accuracy
        train_accuracies.append( np.mean(batch_accuracies) )

        # and get average losses across the batches
        losses[epochi] = np.mean(batch_losses)

        # test accuracy
        x, y = next(iter(test_loader)) # extract X, y from test dataloader
        with torch.no_grad(): # deactivates autograd
          y_hat = wine_net(x)
        test_accuracies.append( 100 * torch.mean(((y_hat > 0) == y).float()).item() )
  
      # function output
      return train_accuracies, test_accuracies, losses








.. GENERATED FROM PYTHON SOURCE LINES 183-186

Train the model
---------------


.. GENERATED FROM PYTHON SOURCE LINES 188-195

.. code-block:: Python

    wine_net = WineNet()
    train_accuracies, test_accuracies, losses = train_the_model(
      wine_net,
      train_loader,
      test_loader,
      )








.. GENERATED FROM PYTHON SOURCE LINES 196-199

Compute the accuracy, precision, recall, and F1 score on the train and test sets
----------------------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 201-205

.. code-block:: Python

    train_predictions = wine_net(train_loader.dataset.tensors[0])
    test_predictions = wine_net(test_loader.dataset.tensors[0])
    test_predictions





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    tensor([[-1.1687e+01],
            [ 3.0081e+00],
            [-7.0877e+00],
            [ 1.0964e+00],
            [-2.5252e+00],
            [ 3.4451e+00],
            [-6.4569e+00],
            [ 8.0725e+00],
            [ 2.4752e+00],
            [ 2.0515e+00],
            [-3.9748e+00],
            [ 7.9013e-01],
            [ 2.6517e+00],
            [ 3.4395e+00],
            [ 5.7601e+00],
            [ 6.2797e+00],
            [-7.2085e+00],
            [ 3.4561e+00],
            [-2.9475e+00],
            [ 1.0099e+00],
            [-8.3859e-01],
            [ 9.9582e+00],
            [-1.2056e+00],
            [-2.8718e+00],
            [ 3.6574e-01],
            [ 1.7433e+00],
            [-5.6318e+00],
            [ 4.0833e-01],
            [ 7.2878e+00],
            [ 8.0934e-01],
            [ 3.0906e+00],
            [-8.3292e-03],
            [-9.2356e-01],
            [ 4.4064e+00],
            [-7.2041e-01],
            [ 2.7370e+00],
            [ 2.5889e+00],
            [ 8.5471e-01],
            [ 3.0517e+00],
            [ 2.4752e+00],
            [ 6.1741e+00],
            [ 3.8722e+00],
            [-4.2024e+00],
            [-7.5761e-01],
            [-1.2977e+00],
            [-2.1738e+00],
            [-6.1513e-01],
            [ 1.7323e+00],
            [-4.9373e+00],
            [-8.3652e-01],
            [ 3.7946e+00],
            [ 4.2757e+00],
            [ 8.1717e-01],
            [ 1.3514e+00],
            [ 2.1684e-01],
            [ 3.0785e+00],
            [-1.1543e-01],
            [-4.0815e+00],
            [-4.9185e+00],
            [-1.0774e+00],
            [ 3.1932e-01],
            [-5.5150e-01],
            [ 8.7100e+00],
            [-5.2557e+00],
            [-8.5434e+00],
            [-3.8727e+00],
            [ 1.8327e+00],
            [-8.4136e+00],
            [-7.5064e+00],
            [ 1.5162e+00],
            [ 3.0306e+00],
            [-4.6184e+00],
            [ 2.6542e+00],
            [-2.8718e+00],
            [ 5.5115e+00],
            [-1.3152e+00],
            [-5.0644e+00],
            [ 3.4047e+00],
            [ 6.1800e+00],
            [ 7.9200e+00],
            [ 3.6670e+00],
            [ 1.8289e+00],
            [ 7.7576e-01],
            [ 2.4945e+00],
            [-1.7518e-01],
            [-1.0107e+01],
            [-9.6352e+00],
            [-1.1763e+00],
            [-3.2802e+00],
            [ 2.1862e+00],
            [-4.3513e+00],
            [ 6.9389e+00],
            [ 9.3273e-01],
            [-3.5958e+00],
            [-1.2071e+01],
            [-7.3259e+00],
            [-1.1648e+01],
            [ 7.3712e+00],
            [ 5.0427e+00],
            [ 2.6951e+00],
            [ 6.1800e+00],
            [ 1.5390e+00],
            [ 3.4853e+00],
            [ 4.4101e+00],
            [ 1.0133e+00],
            [-1.3858e+00],
            [-2.1738e+00],
            [-2.3336e+00],
            [ 2.5590e+00],
            [ 2.1414e+00],
            [-3.4855e-01],
            [ 2.4237e+00],
            [ 4.6765e+00],
            [-7.1353e+00],
            [ 4.1111e+00],
            [ 6.1800e+00],
            [ 5.2344e+00],
            [ 1.3255e+01],
            [ 4.0609e+00],
            [-7.3619e+00],
            [ 6.5135e+00],
            [-4.4960e+00],
            [ 3.4303e+00],
            [ 5.8993e+00],
            [-2.8042e-01],
            [ 1.3613e+00],
            [ 9.7761e-01],
            [ 2.1751e-01],
            [ 2.3068e+00],
            [-4.2121e+00],
            [-2.6415e+00],
            [ 2.5991e-01],
            [-6.7101e+00],
            [-6.5558e-02],
            [-1.9022e+00],
            [ 4.9063e+00],
            [-9.5740e-01],
            [ 1.7841e+00],
            [-4.1111e-01],
            [-5.0551e+00],
            [-1.2090e+00],
            [ 6.7526e+00],
            [-4.1278e-01],
            [-2.1164e+00],
            [ 4.7043e+00],
            [-6.6553e-01],
            [-1.1898e+00],
            [ 4.0101e-01],
            [ 6.9641e+00],
            [ 4.7756e+00],
            [ 4.6142e+00],
            [-7.7287e+00],
            [ 1.2003e+00],
            [ 1.2124e+00],
            [ 2.4130e+00],
            [ 2.2275e-02],
            [ 3.7997e+00],
            [-7.5459e-01],
            [-2.3010e+00],
            [ 2.1218e+00]], grad_fn=<AddmmBackward0>)



.. GENERATED FROM PYTHON SOURCE LINES 206-209

Use Scikit Learn to compute the metrics
---------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 211-236

.. code-block:: Python

    from sklearn.metrics import (
      accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
      )

    # initialize a dictionary to store the metrics
    train_metrics = [0, 0, 0, 0]
    test_metrics = [0, 0, 0, 0]

    # compute the metrics on the train set
    true_labels = train_loader.dataset.tensors[1]
    train_predictions = train_predictions > 0
    train_metrics[0] = accuracy_score(true_labels, train_predictions)
    train_metrics[1] = precision_score(true_labels, train_predictions)
    train_metrics[2] = recall_score(true_labels, train_predictions)
    train_metrics[3] = f1_score(true_labels, train_predictions)

    # compute the metrics on the test set
    true_labels = test_loader.dataset.tensors[1]
    test_predictions = test_predictions > 0
    test_metrics[0] = accuracy_score(true_labels, test_predictions)
    test_metrics[1] = precision_score(true_labels, test_predictions)
    test_metrics[2] = recall_score(true_labels, test_predictions)
    test_metrics[3] = f1_score(true_labels, test_predictions)
    print(train_metrics, test_metrics)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [0.9081419624217119, 0.9069767441860465, 0.9212598425196851, 0.9140625] [0.775, 0.8021978021978022, 0.8021978021978022, 0.8021978021978022]




.. GENERATED FROM PYTHON SOURCE LINES 237-240

Plot the metrics
----------------


.. GENERATED FROM PYTHON SOURCE LINES 242-252

.. code-block:: Python

    sns.set_style("darkgrid")
    fig, ax = plt.subplots()
    ax.bar(np.arange(4) -.1, train_metrics, .5)
    ax.bar(np.arange(4) +.1, test_metrics, .5)
    ax.set_xticks([0,1,2,3],['Accuracy','Precision','Recall','F1-score'])
    ax.set_ylim([.6,1])
    ax.legend(['Train','Test'])
    ax.set_title('Performance metrics')
    plt.show()




.. image-sg:: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_001.png
   :alt: Performance metrics
   :srcset: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 253-256

Show the confusion matrices
---------------------------


.. GENERATED FROM PYTHON SOURCE LINES 258-259

Confusion matrices

.. GENERATED FROM PYTHON SOURCE LINES 259-299

.. code-block:: Python

    true_labels_train = train_loader.dataset.tensors[1]
    true_labels_test = test_loader.dataset.tensors[1]
    train_conf = confusion_matrix(true_labels_train, train_predictions>0)
    test_conf  = confusion_matrix(true_labels_test, test_predictions>0)

    sns.set_style('white')
    fig, axes = plt.subplots(1,2,figsize=(10,4))

    # confmat during TRAIN
    axes[0].imshow(train_conf, 'Blues', vmax=len(train_predictions)/2)
    axes[0].set_xticks([0,1])
    axes[0].set_yticks([0,1])
    axes[0].set_xticklabels(['bad','good'])
    axes[0].set_yticklabels(['bad','good'])
    axes[0].set_xlabel('Predicted quality')
    axes[0].set_ylabel('True quality')
    axes[0].set_title('TRAIN confusion matrix')

    # add text labels
    text_kwargs = dict(ha='center', va='center')
    axes[0].text(0,0,f'True negatives:\n{train_conf[0, 0]}' , **text_kwargs)
    axes[0].text(0,1,f'False negatives:\n{train_conf[1, 0]}', **text_kwargs)
    axes[0].text(1,1,f'True positives:\n{train_conf[1, 1]}' , **text_kwargs)
    axes[0].text(1,0,f'False positives:\n{train_conf[0, 1]}', **text_kwargs)

    # confmat during TEST
    axes[1].imshow(test_conf,'Blues',vmax=len(test_predictions)/2)
    axes[1].set_xticks([0,1])
    axes[1].set_yticks([0,1])
    axes[1].set_xticklabels(['bad','good'])
    axes[1].set_yticklabels(['bad','good'])
    axes[1].set_xlabel('Predicted quality')
    axes[1].set_ylabel('True quality')
    axes[1].set_title('TEST confusion matrix')

    # add text labels
    axes[1].text(0,0,f'True negatives:\n{test_conf[0,0]}', **text_kwargs)
    axes[1].text(0,1,f'False negatives:\n{test_conf[1,0]}', **text_kwargs)
    axes[1].text(1,1,f'True positives:\n{test_conf[1,1]}' , **text_kwargs)
    axes[1].text(1,0,f'False positives:\n{test_conf[0,1]}', **text_kwargs)
    plt.show()


.. image-sg:: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_002.png
   :alt: TRAIN confusion matrix, TEST confusion matrix
   :srcset: /auto_examples/deep_learning/images/sphx_glr_plot_arfp_wine_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (7 minutes 22.625 seconds)


.. _sphx_glr_download_auto_examples_deep_learning_plot_arfp_wine.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_arfp_wine.ipynb <plot_arfp_wine.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_arfp_wine.py <plot_arfp_wine.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_arfp_wine.zip <plot_arfp_wine.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
